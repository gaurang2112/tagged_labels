{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2G9mftjJa60e/WPDm7jBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaurang2112/tagged_labels/blob/master/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UukuwxEtfwgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cb1367de-8364-45e1-e627-0156b848706d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuqapSUXfRdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_file_address = 'gdrive/My Drive/Colab Notebooks/ner_dataset.csv'\n",
        "\n",
        "df_data = pd.read_csv(data_file_address,sep=\",\",encoding=\"latin1\").fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLCVRuPChpQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "4e0c1003-33af-42d9-a7e8-cb1eda932001"
      },
      "source": [
        "df_data.head(n=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>troops</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "5   Sentence: 1        through   IN      O\n",
              "6   Sentence: 1         London  NNP  B-geo\n",
              "7   Sentence: 1             to   TO      O\n",
              "8   Sentence: 1        protest   VB      O\n",
              "9   Sentence: 1            the   DT      O\n",
              "10  Sentence: 1            war   NN      O\n",
              "11  Sentence: 1             in   IN      O\n",
              "12  Sentence: 1           Iraq  NNP  B-geo\n",
              "13  Sentence: 1            and   CC      O\n",
              "14  Sentence: 1         demand   VB      O\n",
              "15  Sentence: 1            the   DT      O\n",
              "16  Sentence: 1     withdrawal   NN      O\n",
              "17  Sentence: 1             of   IN      O\n",
              "18  Sentence: 1        British   JJ  B-gpe\n",
              "19  Sentence: 1         troops  NNS      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXd_VpLKhy-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGr8G2J5h4s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tresQO_5h8MY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "83b58b93-2611-4b8f-82b2-11e60eed8733"
      },
      "source": [
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbKMSJJ7iAII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d576ad86-ecb3-4621-ba74-780964d41063"
      },
      "source": [
        "poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "print(poses[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrfIi_IYi4Qa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "063a13f1-1dc1-4c61-847e-7248eaa42a79"
      },
      "source": [
        "# Get tag labels data\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ-I_0S3i6CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags_vals = list(set(df_data[\"Tag\"].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pilzwycLjPsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add X  label for word piece support\n",
        "# Add [CLS] and [SEP] as BERT need\n",
        "tags_vals.append('X')\n",
        "tags_vals.append('[CLS]')\n",
        "tags_vals.append('[SEP]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm5IghpxxCPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tags_vals = set(tags_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LLOJ5V1xGHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cd8b9776-47ae-4b1d-ee57-c377b6da2894"
      },
      "source": [
        "tags_vals\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art',\n",
              " 'B-eve',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-nat',\n",
              " 'B-org',\n",
              " 'B-per',\n",
              " 'B-tim',\n",
              " 'I-art',\n",
              " 'I-eve',\n",
              " 'I-geo',\n",
              " 'I-gpe',\n",
              " 'I-nat',\n",
              " 'I-org',\n",
              " 'I-per',\n",
              " 'I-tim',\n",
              " 'O',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQ2GX7wxIxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHenOl5BxOOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "3f9e90f9-4e79-4c89-e5ac-11ce7020e1be"
      },
      "source": [
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "tag2name\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-geo',\n",
              " 1: 'I-tim',\n",
              " 2: 'B-tim',\n",
              " 3: 'I-org',\n",
              " 4: 'B-per',\n",
              " 5: 'I-art',\n",
              " 6: 'I-per',\n",
              " 7: 'I-eve',\n",
              " 8: 'I-gpe',\n",
              " 9: 'O',\n",
              " 10: 'B-org',\n",
              " 11: 'I-nat',\n",
              " 12: 'B-nat',\n",
              " 13: 'B-gpe',\n",
              " 14: 'B-art',\n",
              " 15: 'I-geo',\n",
              " 16: 'B-eve',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW7USOq1yu3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tBddSDW9p4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "74c489ac-82d7-4677-ae09-813305cc2b31"
      },
      "source": [
        "pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=d82f513855cb5074e9d3723dbc767dbe2117e4ab470aef110c0ef62c23358050\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpaz_Zmw8nFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCGMy1uf9Png",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "0b2b8eed-42ff-4931-9ebf-f04bdc3366cc"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 8.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 27.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 33.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 18.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 16.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 18.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 13.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 14.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 15.2MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 14.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 14.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 14.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 14.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 14.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 14.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 14.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983kB 14.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 51kB/s eta 0:00:02\r\u001b[K     |██████████████████████████████▏ | 1.0MB 51kB/s eta 0:00:02\r\u001b[K     |██████████████████████████████▌ | 1.0MB 51kB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 51kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 51kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 51kB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 51kB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 29.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7623eb8daf551f4b1e37ac86043507aed5a7779992b9e9fcf1059321c9d8e6dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I7O8spb8pi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00022b18-abd0-48af-c571-904477c7ede9"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForTokenClassification, AdamW"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqxtUiDt8y7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpRK08-r92S9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87027f66-9936-4b3c-9a07-dda9b386a52a"
      },
      "source": [
        "\n",
        "n_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIWXicGD95GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = \"gdrive/My Drive/Colab Notebooks/bert-base-cased-vocab.txt\"\n",
        "max_len  = 45\n",
        "tokenizer=BertTokenizer(vocab_file=vocabulary,do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAUEEM_2Be6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "b3e50a4e-98b8-403e-cf4c-d58b7ed4023c"
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "i_inc = 0\n",
        "for word_list,label in (zip(sentences,labels)):\n",
        "    temp_lable = []\n",
        "    temp_token = []\n",
        "    \n",
        "    # Add [CLS] at the front \n",
        "    temp_lable.append('[CLS]')\n",
        "    temp_token.append('[CLS]')\n",
        "    \n",
        "    for word,lab in zip(word_list,label):\n",
        "        token_list = tokenizer.tokenize(word)\n",
        "        for m,token in enumerate(token_list):\n",
        "            temp_token.append(token)\n",
        "            if m==0:\n",
        "                temp_lable.append(lab)\n",
        "            else:\n",
        "                temp_lable.append('X')  \n",
        "                \n",
        "    # Add [SEP] at the end\n",
        "    temp_lable.append('[SEP]')\n",
        "    temp_token.append('[SEP]')\n",
        "    \n",
        "    tokenized_texts.append(temp_token)\n",
        "    word_piece_labels.append(temp_lable)\n",
        "    \n",
        "    if 5 > i_inc:\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_lable)))\n",
        "        print(\"lables:%s\"%(\" \".join(temp_lable)))\n",
        "    i_inc +=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.0,len:28\n",
            "texts:[CLS] Thousands of demons ##tra ##tors have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . [SEP]\n",
            "No.0,len:28\n",
            "lables:[CLS] O O O X X O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O [SEP]\n",
            "No.1,len:29\n",
            "texts:[CLS] Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an I ##A ##EA surveillance system begins functioning . [SEP]\n",
            "No.1,len:29\n",
            "lables:[CLS] B-gpe O O O O O O O O O O O O O O B-tim O O O B-org X X O O O O O [SEP]\n",
            "No.2,len:44\n",
            "texts:[CLS] He ##lic ##op ##ter guns ##hips Saturday pounded militant hide ##outs in the Or ##ak ##zai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South W ##azi ##rist ##an . [SEP]\n",
            "No.2,len:44\n",
            "lables:[CLS] O X X X O X B-tim O O O X O O B-geo X X O O O O O B-org O O O O O O O O O O O O O O B-geo I-geo X X X O [SEP]\n",
            "No.3,len:16\n",
            "texts:[CLS] They left after a tense hour - long stand ##off with riot police . [SEP]\n",
            "No.3,len:16\n",
            "lables:[CLS] O O O O O O X X O X O O O O [SEP]\n",
            "No.4,len:47\n",
            "texts:[CLS] U . N . relief coordinator Jan E ##gel ##and said Sunday , U . S . , Indonesian and Australian military helicopters are ferry ##ing out food and supplies to remote areas of western Ace ##h province that ground crews can not reach . [SEP]\n",
            "No.4,len:47\n",
            "lables:[CLS] B-geo X X X O O B-per I-per X X O B-tim O B-geo X X X O B-gpe O B-gpe O O O O X O O O O O O O O O B-geo X O O O O O O O O [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FkKuVDdBric",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8332ac6e-49d4-4e0a-838a-48c1927192df"
      },
      "source": [
        "# Make text token into id\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIeL7qfdB7x8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cec44c7d-8a1f-46d7-fda0-395b25971e33"
      },
      "source": [
        "# Make label into id, pad with \"O\" meaning others\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                     maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "print(tags[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  9  9  9 17 17  9  9  9  0  9  9  9  9  9  0  9  9  9  9  9 13  9  9\n",
            "  9  9  9 19  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL9LjCUTCAJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# For fine tune of predict, with token mask is 1,pad token is 0\n",
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "attention_masks[0];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RprTZ5MCCE6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since only one sentence, all the segment set to 0\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "segment_ids[0];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPs_1hcLCizp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(input_ids, tags,attention_masks,segment_ids, \n",
        "                                                            random_state=4, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-eL7782CndB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66c15c85-c760-417b-c097-72a2c659f1f4"
      },
      "source": [
        "len(tr_inputs),len(val_inputs),len(tr_segs),len(val_segs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33571, 14388, 33571, 14388)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_JAp9GiCpcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUtDtCkdCujj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set batch num\n",
        "batch_num = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvkm7d3_Cw31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Only set token embedding, attention embedding, no segment embedding\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVLvN3g-Czca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_address = 'gdrive/My Drive/Colab Notebooks/bert'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "853BBJgVi2WU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "842112bf-e8b6-4d9a-edb5-45a94bc862f9"
      },
      "source": [
        "\n",
        "# Will load config and weight with from_pretrained()\n",
        "model = BertForTokenClassification.from_pretrained(model_file_address, num_labels=len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at gdrive/My Drive/Colab Notebooks/bert were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at gdrive/My Drive/Colab Notebooks/bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV9caOpfi5rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model to GPU,if you are using GPU machine\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMgKhtXRIPEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add multi GPU support\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBO6jwelIV2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set epoch and grad max num\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyDbOA7RIYjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Cacluate train optimiazaion num\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dPkWUMJIa9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True: fine tuning all the layers \n",
        "# False: only fine tuning the classifier layers\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvoVwLuWIdm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6LIbTa2IgDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TRAIN loop\n",
        "model.train();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E8Z7-N_IiHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f5bd0b9e-3e25-44d6-a6da-784b0da5170b"
      },
      "source": [
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "        attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 33571\n",
            "  Batch size = 32\n",
            "  Num steps = 5250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 1/5 [08:52<35:31, 532.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1443140874727779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [17:44<26:37, 532.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.06783378802353536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [26:36<17:44, 532.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.05225885557712147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [35:29<08:52, 532.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.03961700090678592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [44:21<00:00, 532.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.029557131936647586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAmYxvzNIpHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_out_address = 'gdrive/My Drive/Colab Notebooks/en09'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY1VTbXoT43y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Make dir if not exits\n",
        "if not os.path.exists(bert_out_address):\n",
        "        os.makedirs(bert_out_address)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBROXYOtT67z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save a trained model, configuration and tokenizer\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMYOmEgHUMEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(bert_out_address, \"config.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3_c2zwuUffg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "107e27eb-22aa-4471-b209-eaf64a19bff3"
      },
      "source": [
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(bert_out_address)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gdrive/My Drive/Colab Notebooks/en09/vocab.txt',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOn9BEZwUmim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E_5cl5NUqWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set model to GPU\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHbQmhqNUuDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wls-BpMxUv8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalue loop\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_rXzhRmUy5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "85b3809a-5666-440a-bc00-91651e291bec"
      },
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, label_ids = batch\n",
        "    \n",
        "#     if step > 2:\n",
        "#         break\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "        attention_mask=input_mask,)\n",
        "        # For eval mode, the first result of outputs is logits\n",
        "        logits = outputs[0] \n",
        "    \n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    \n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    \n",
        "    \n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predict one\n",
        "        temp_2 = []\n",
        "        \n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m:\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "            else:\n",
        "                break\n",
        "        \n",
        "            \n",
        "        y_true.append(temp_1)\n",
        "        y_pred.append(temp_2)\n",
        "\n",
        "        \n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Get acc , recall, F1 result report\n",
        "report = classification_report(y_true, y_pred,digits=4)\n",
        "\n",
        "# Save the report into file\n",
        "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    print(\"\\n%s\"%(report))\n",
        "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "    \n",
        "    writer.write(\"f1 socre:\\n\")\n",
        "    writer.write(str(f1_score(y_true, y_pred)))\n",
        "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
        "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
        "    writer.write(\"\\n\\n\")  \n",
        "    writer.write(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =14388\n",
            "  Batch size = 32\n",
            "f1 socre: 0.833828\n",
            "Accuracy score: 0.971185\n",
            "***** Eval results *****\n",
            "\n",
            "           precision    recall  f1-score   support\n",
            "\n",
            "      tim     0.8610    0.8793    0.8701      6016\n",
            "      gpe     0.9475    0.9499    0.9487      4830\n",
            "      geo     0.8273    0.9075    0.8655     11066\n",
            "      org     0.7227    0.6859    0.7038      5954\n",
            "      per     0.7880    0.7837    0.7859      5123\n",
            "      eve     0.4524    0.4176    0.4343        91\n",
            "      art     0.2558    0.1679    0.2028       131\n",
            "      nat     0.4000    0.5306    0.4561        49\n",
            "\n",
            "micro avg     0.8229    0.8450    0.8338     33260\n",
            "macro avg     0.8222    0.8450    0.8328     33260\n",
            "\n",
            "f1 socre: 0.833828\n",
            "Accuracy score: 0.971185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFhzeU5jVJbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tag to index, must be the same as we training\n",
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prmHVTbaWInO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN5uS9-cWLQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Model we trained before, the dir containing pytorch_model.bin and vocab.txt\n",
        "save_model_address = 'gdrive/My Drive/Colab Notebooks/en09'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltBZKns0WXfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model = BertForTokenClassification.from_pretrained(save_model_address,num_labels=len(tag2idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIKHUhsSWZvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, our save model address containing pytorch_model.bin and vocab.txt\n",
        "# So, we can load the tokenzier from the same dir as the save model address\n",
        "tokenizer = BertTokenizer.from_pretrained(save_model_address,do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmTIplz6WfTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set max sentence length, must be the same as our training process\n",
        "max_len  = 45"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD1G9xcodF5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linedata=[]\n",
        "with open(\"gdrive/My Drive/Colab Notebooks/txts/tim_burns_cv.txt\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()      \n",
        "        linedata.append(line.split('\\t'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unp2LkU-es9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import numpy as np\n",
        " arr = np.array(linedata)\n",
        " test_arr = arr.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES-M5B6vfENF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture cap --no-stderr\n",
        "for j in range(len(test_arr)) :\n",
        "  k=j+1\n",
        "  tokenized_texts = []\n",
        "  temp_token = []\n",
        "  # Add [CLS] at the front \n",
        "  temp_token.append('[CLS]')\n",
        "  token_list = tokenizer.tokenize(test_arr[j])\n",
        "  for m,token in enumerate(token_list):\n",
        "      temp_token.append(token)\n",
        "  # Trim the token to fit the length requirement\n",
        "  if len(temp_token) > max_len-1:\n",
        "      temp_token= temp_token[:max_len-1]    \n",
        "  # Add [SEP] at the end\n",
        "  temp_token.append('[SEP]') \n",
        "  tokenized_texts.append(temp_token)   \n",
        "  # Make text token into id\n",
        "  input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                            maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "  # For fine tune of predict, with token mask is 1,pad token is 0\n",
        "  attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "  segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  segment_ids = torch.tensor(segment_ids)\n",
        "  save_model.eval();\n",
        "  # Get model predict result\n",
        "  with torch.no_grad():\n",
        "          outputs = save_model(input_ids, token_type_ids=None,\n",
        "          attention_mask=None,)\n",
        "          # For eval mode, the first result of outputs is logits\n",
        "          logits = outputs[0]\n",
        "  # Make logits into numpy type predict result\n",
        "  # The predict result contain each token's all tags predict result\n",
        "  predict_results = logits.detach().cpu().numpy()     \n",
        "  from scipy.special import softmax\n",
        "  result_array = softmax(predict_results[0])\n",
        "  # Get each token final predict tag index result\n",
        "  result_list = np.argmax(result_array,axis=-1)\n",
        "  for i, mark in enumerate(attention_masks[0]):\n",
        "      if mark>0:\n",
        "          print(\"sentence :\"+ str(k))       \n",
        "          print(\"Token:%s\"%(temp_token[i]))\n",
        "          #print(\"Tag:%s\"%(result_list[i]))\n",
        "          print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
        "          #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
        "          print()\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I3jOVsGl7oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('gdrive/My Drive/Colab Notebooks/txts_output/tim_burns_cv_out.txt', 'a') as f:\n",
        "      f.write(cap.stdout)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ua2RL2Yn7cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}